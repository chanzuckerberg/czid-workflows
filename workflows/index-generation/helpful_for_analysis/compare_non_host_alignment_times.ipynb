{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f6a11822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from collections import namedtuple\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff4dabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you set the appropriate AWS_PROFILE in terminal before launching notebook\n",
    "\n",
    "# Initialize the Step Functions, s3, and CloudWatch Logs clients\n",
    "sfn_client = boto3.client(\"stepfunctions\")\n",
    "s3_client = boto3.client('s3')\n",
    "logs_client = boto3.client('logs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fe1d2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_and_key(s3_path):\n",
    "    # get the path to the non_host alignment log\n",
    "    s3_path_parts = s3_path.strip(\"s3://\").split(\"/\")\n",
    "    bucket = s3_path_parts[0]\n",
    "    key = \"/\".join(s3_path_parts[1::])\n",
    "    \n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "def count_chunks(index_s3_path):\n",
    "    try:\n",
    "        bucket, key = get_bucket_and_key(index_s3_path)\n",
    "        # List objects within the bucket\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        contents = []\n",
    "        for page in paginator.paginate(Bucket=bucket, Prefix=key):\n",
    "            contents.append(page.get('Contents', []))\n",
    "        \n",
    "        unqiue_keys = set()\n",
    "        for page in contents:\n",
    "            for c in page:\n",
    "                filename = c['Key'].split(\"/\")[-1]\n",
    "                unqiue_keys.add(filename)\n",
    "                \n",
    "        return len(unqiue_keys)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    \n",
    "\n",
    "def get_execution_alignment_times(execution_arn):\n",
    "    # Get the execution history\n",
    "    execution_history = sfn_client.get_execution_history(\n",
    "        executionArn=execution_arn\n",
    "    )\n",
    "    \n",
    "    # get the job inputs to get the s3 bucket\n",
    "    event_input = json.loads(execution_history[\"events\"][0][\"executionStartedEventDetails\"][\"input\"])\n",
    "    s3_wd_uri = event_input[\"Input\"][\"NonHostAlignment\"][\"s3_wd_uri\"]\n",
    "    diamond_index_path = event_input[\"Input\"][\"NonHostAlignment\"][\"diamond_db\"]\n",
    "    minimap_index_path = event_input[\"Input\"][\"NonHostAlignment\"][\"minimap2_db\"]\n",
    "    \n",
    "    # get the chunks for diamond and minimap\n",
    "    diamond_chunks = count_chunks(diamond_index_path)\n",
    "    minimap_chunks = count_chunks(minimap_index_path)\n",
    "    \n",
    "    # get the path to the non_host alignment log\n",
    "    bucket_name, key = get_bucket_and_key(s3_wd_uri)\n",
    "    key = f\"{key}/non_host_alignment_status2.json\"\n",
    "    \n",
    "    # Get the object from S3\n",
    "    obj = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "\n",
    "    # Read the file's content\n",
    "    file_content = json.loads(obj['Body'].read().decode('utf-8'))\n",
    "\n",
    "\n",
    "    # get alignment times: \n",
    "    diamond_time_in_seconds = float(file_content[\"diamond_out\"][\"end_time\"]) - float(file_content[\"diamond_out\"][\"start_time\"])\n",
    "    minimap_time_in_seconds = float(file_content[\"minimap2_out\"][\"end_time\"]) - float(file_content[\"minimap2_out\"][\"start_time\"])\n",
    "\n",
    "    # get the time in minutes\n",
    "    diamond_time_in_mins = diamond_time_in_seconds/60\n",
    "    minimap_time_in_mins = minimap_time_in_seconds/60\n",
    "    \n",
    "    sfn_info = namedtuple(\"sfn_info\", [\n",
    "        \"diamond_time_in_mins\", \n",
    "        \"minimap_time_in_mins\", \n",
    "        \"diamond_index_path\", \n",
    "        \"minimap_index_path\", \n",
    "        \"diamond_chunks\", \n",
    "        \"minimap_chunks\"\n",
    "    ])\n",
    "    \n",
    "    return sfn_info(\n",
    "        diamond_time_in_mins, \n",
    "        minimap_time_in_mins, \n",
    "        diamond_index_path, \n",
    "        minimap_index_path, \n",
    "        diamond_chunks, \n",
    "        minimap_chunks\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "630dfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with execution ARNs (right now these are stubbed)\n",
    "\n",
    "execution_arn_no_compression = 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-150-32175-35212-20240122120219'\n",
    "execution_arn_w_compression = 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1166-32169-35209-20240122112059'\n",
    "\n",
    "def compare_two_runs(run1_arn, run2_arn): # usually run1 is the compressed DB\n",
    "    diamond_1, minimap_1, _, _, _, _ = get_execution_alignment_times(run1_arn)\n",
    "    diamond_2, minimap_2, _, _, _, _ = get_execution_alignment_times(run2_arn)\n",
    "\n",
    "    time_diff_diamond = diamond_1 / diamond_2\n",
    "    time_diff_minimap = minimap_1 / minimap_2\n",
    "\n",
    "    print(f\"diamond: {time_diff_diamond}\")\n",
    "    print(f\"minimap: {time_diff_minimap}\")\n",
    "    \n",
    "    return time_diff_diamond, time_diff_minimap\n",
    "\n",
    "# compare_two_runs(execution_arn_no_compression, execution_arn_w_compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fe3f8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = {\n",
    "    'Cookie': 'x',  \n",
    "}\n",
    "\n",
    "def get_execution_arn(sample_id):\n",
    "    url = f'https://staging.czid.org/samples/{sample_id}/pipeline_runs'\n",
    "    response = requests.get(url, cookies=cookies)\n",
    "    if response.status_code == 200:\n",
    "        sfn = [s for s in response.text.split(\" \") if \"arn:aws\" in s][0]\n",
    "        execution_arn = sfn.split(\">\")[1].rstrip(\"</a\")\n",
    "        return execution_arn\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "58e81e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_name_to_id_for_project(project_id):\n",
    "    project_url = f\"https://staging.czid.org/samples/index_v2.json?projectId={project_id}&domain=all_data&offset=0&listAllIds=true&basic=false&workflow=short-read-mngs\"\n",
    "    response = requests.get(project_url, cookies=cookies)\n",
    "    sample_json = response.json()\n",
    "    \n",
    "    sample_name_to_id = {\n",
    "    x[\"name\"]: x[\"id\"]\n",
    "    for x in sample_json[\"samples\"]\n",
    "    }\n",
    "    \n",
    "    return sample_name_to_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3d4881ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1_arn = get_execution_arn(29045)\n",
    "sample_2_arn = get_execution_arn(28408)\n",
    "\n",
    "print(sample_1_arn)\n",
    "print(sample_2_arn)\n",
    "\n",
    "sample_1_alignment_times = get_execution_alignment_times(sample_1_arn)\n",
    "sample_2_alignment_times = get_execution_alignment_times(sample_2_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8c7c9ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diamond: 0.5219304184739638\n",
      "minimap: 0.5593416247014229\n",
      "error getting UnAmbiguouslyMapped_ds.soil sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27094-31587-20230828135316'\n",
      "error getting UnAmbiguouslyMapped_ds.nycsm sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27095-31583-20230828135254'\n",
      "error getting UnAmbiguouslyMapped_ds.hous2 sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27096-31581-20230828135251'\n",
      "error getting UnAmbiguouslyMapped_ds.hous1 sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27097-31585-20230828135255'\n",
      "error getting UnAmbiguouslyMapped_ds.gut sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27098-31584-20230828135254'\n",
      "error getting UnAmbiguouslyMapped_ds.cityparks sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27099-31586-20230828135304'\n",
      "error getting UnAmbiguouslyMapped_ds.buccal sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27100-31582-20230828135253'\n",
      "error getting UnAmbiguouslyMapped_ds.7 sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27101-31591-20230828135323'\n",
      "error getting atcc_staggered sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27092-31588-20230828135320'\n",
      "error getting atcc_even sample\n",
      "An error occurred (ExecutionDoesNotExist) when calling the GetExecutionHistory operation: Execution Does Not Exist: 'arn:aws:states:us-west-2:732052188396:execution:idseq-swipe-staging-short-read-mngs-wdl:idseq-staging-1051-27093-31589-20230828135320'\n",
      "diamond: 1.1413587145227573\n",
      "minimap: 1.006168177704185\n",
      "diamond: 1.1082711995204277\n",
      "minimap: 0.862069295162505\n",
      "diamond: 1.4004743587126476\n",
      "minimap: 0.9432830197531593\n",
      "diamond: 1.0307945040742756\n",
      "minimap: 0.8646724445655666\n",
      "diamond: 0.7564907779264083\n",
      "minimap: 0.9475541316319527\n",
      "diamond: 1.6715550658406804\n",
      "minimap: 1.2758480656763322\n",
      "diamond: 1.1958892794033098\n",
      "minimap: 0.7528753748971863\n",
      "diamond: 2.179437523293071\n",
      "minimap: 1.33375714914909\n",
      "diamond: 1.517813105943389\n",
      "minimap: 1.115554676283819\n",
      "diamond: 1.3364693366652127\n",
      "minimap: 0.985358111133992\n",
      "diamond: 0.9393788356280435\n",
      "minimap: 0.8033149998969356\n",
      "diamond: 0.9158031283711716\n",
      "minimap: 0.9808303149829664\n",
      "diamond: 1.6157320886581334\n",
      "minimap: 1.2319208609134766\n",
      "diamond: 0.6501786220980968\n",
      "minimap: 0.7706553376403747\n",
      "diamond: 1.3159700879991234\n",
      "minimap: 1.3094336568267304\n",
      "diamond: 1.606573537215923\n",
      "minimap: 1.184695443169277\n",
      "diamond: 1.2766908328725703\n",
      "minimap: 1.4735588334290821\n",
      "diamond: 1.2297858570995672\n",
      "minimap: 1.3165801755482516\n",
      "diamond: 1.1659150321562965\n",
      "minimap: 1.3063464582222877\n"
     ]
    }
   ],
   "source": [
    "def compare_projects(project_name_1, project_id_1, project_name_2, project_id_2):\n",
    "    project_1_samples = get_sample_name_to_id_for_project(project_id_1)\n",
    "    project_2_samples = get_sample_name_to_id_for_project(project_id_2)\n",
    "    \n",
    "    records = []\n",
    "    # project 1 is the primary (usually compressed) dataset\n",
    "    for name, i in project_1_samples.items():\n",
    "        if name in project_2_samples.keys():\n",
    "            try:\n",
    "                sample_1_arn = get_execution_arn(i)\n",
    "                sample_1_alignment_times = get_execution_alignment_times(sample_1_arn)\n",
    "                sample_1_total_alignment_time_diamond = sample_1_alignment_times[0]* sample_1_alignment_times[4]\n",
    "                sample_1_total_alignment_time_minimap = sample_1_alignment_times[1]* sample_1_alignment_times[5]\n",
    "            except Exception as e:\n",
    "                print(f\"error getting {name} sample\")\n",
    "                print(e)\n",
    "                sample_1_alignment_times = [\"ARN DNE\"]*6\n",
    "                sample_1_total_alignment_time_diamond=\"NA\"\n",
    "                sample_1_total_alignment_time_minimap=\"NA\"\n",
    "\n",
    "\n",
    "            try:\n",
    "                sample_2_arn = get_execution_arn(project_2_samples[name])\n",
    "                sample_2_alignment_times = get_execution_alignment_times(sample_2_arn)\n",
    "                sample_2_total_alignment_time_diamond = sample_2_alignment_times[0]* sample_2_alignment_times[4]\n",
    "                sample_2_total_alignment_time_minimap = sample_2_alignment_times[1]* sample_2_alignment_times[5]\n",
    "            except Exception as e:\n",
    "                print(f\"error getting {name} sample\")\n",
    "                print(e)\n",
    "                sample_2_alignment_times = [\"ARN DNE\"]*6\n",
    "                sample_2_total_alignment_time_diamond=\"NA\"\n",
    "                sample_2_total_alignment_time_minimap=\"NA\"\n",
    "\n",
    "            if (\"ARN DNE\" in sample_1_alignment_times or \"ARN DNE\" in sample_2_alignment_times):\n",
    "                diff = [\"UNABLE TO COMPARE, ARN DNE\"]*2\n",
    "            else:\n",
    "                diff = compare_two_runs(sample_1_arn, sample_2_arn)\n",
    "\n",
    "            records.append(\n",
    "                [\n",
    "                    project_name_1, \n",
    "                    project_name_2,\n",
    "                    name,\n",
    "                    sample_1_alignment_times.diamond_time_in_mins, \n",
    "                    sample_1_alignment_times.minimap_time_in_mins,\n",
    "                    sample_1_alignment_times.diamond_index_path,\n",
    "                    sample_1_alignment_times.minimap_index_path,\n",
    "                    sample_1_alignment_times.diamond_chunks,\n",
    "                    sample_1_alignment_times.minimap_chunks,\n",
    "                    sample_1_total_alignment_time_diamond,\n",
    "                    sample_1_total_alignment_time_minimap,\n",
    "                    sample_2_alignment_times.diamond_time_in_mins,\n",
    "                    sample_2_alignment_times.minimap_time_in_mins,\n",
    "                    sample_2_alignment_times.diamond_index_path,\n",
    "                    sample_2_alignment_times.minimap_index_path,\n",
    "                    sample_2_alignment_times.diamond_chunks,\n",
    "                    sample_2_alignment_times.minimap_chunks,\n",
    "                    sample_2_total_alignment_time_diamond,\n",
    "                    sample_2_total_alignment_time_minimap,\n",
    "                    diff[0],\n",
    "                    diff[1]\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "    return records\n",
    "        \n",
    "    \n",
    "records = compare_projects(\n",
    "    \"20210122_unclobbered_0-9_1000_31\", \n",
    "    1125, \n",
    "    \"NCBI DB Compression -- uncompressed NT-NR baseline\", \n",
    "    1051\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c68b5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Specify the filename\n",
    "filename = \"alignment_time_differences_in_minutes.csv\"\n",
    "\n",
    "# Writing to csv file\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\n",
    "        \"project_name_1\", \n",
    "        \"project_name_2\",\n",
    "        \"sample_name\",\n",
    "        \"sample_1_alignment_time_diamond\", \n",
    "        \"sample_1_alignment_times_minimap\",\n",
    "        \"sample_1_diamond_path\",\n",
    "        \"sample_1_minimap_path\",\n",
    "        \"sample_1_diamond_chunk_count\",\n",
    "        \"sample_1_minimap_chunk_count\",\n",
    "        \"sample_1_total_alignment_time_diamond\",\n",
    "        \"sample_1_total_alignment_time_minimap\",\n",
    "        \"sample_2_alignment_times_diamond\",\n",
    "        \"sample_2_alignment_times_minimap\",\n",
    "        \"sample_2_diamond_path\",\n",
    "        \"sample_2_minimap_path\",\n",
    "        \"sample_2_diamond_chunk_count\",\n",
    "        \"sample_2_minimap_chunk_count\",\n",
    "        \"sample_2_total_alignment_time_diamond\",\n",
    "        \"sample_2_total_alignment_time_minimap\",\n",
    "        \"time_diff_diamond\",\n",
    "        \"time_diff_minimap\"\n",
    "    ])  \n",
    "    # Writing the data into the file\n",
    "    csvwriter.writerows(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d44d87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "c = pd.read_csv(\"alignment_time_differences_in_minutes.csv\")\n",
    "c.head()\n",
    "\n",
    "c[\n",
    "    [\n",
    "        \"project_name_1\", \n",
    "        \"project_name_2\", \n",
    "        \"sample_1_total_alignment_time_minimap\", \n",
    "        \"sample_2_total_alignment_time_minimap\",\n",
    "        \"sample_1_total_alignment_time_diamond\",\n",
    "        \"sample_2_total_alignment_time_diamond\"\n",
    "    ]\n",
    "].to_csv(\"total_alignment_times_in_mins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c43ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
